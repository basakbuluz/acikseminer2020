{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4gG4FlHdK7N"
   },
   "source": [
    "Kaynak: Dr. Deniz Kılınç\n",
    "\n",
    "Kaynak Kod: https://github.com/denopas/TextProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "AnrOP7iHAPbI",
    "outputId": "909df924-7122-4f41-e183-ea44cd19018b"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 8000\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "C_5iVzJ5Ahhi",
    "outputId": "63c8dbe9-62d2-43ce-92ae-e07573b4f8a4"
   },
   "outputs": [],
   "source": [
    "# TR: Örnek Türkçe dokümanlar \n",
    "# EN: Sample documents in Turkish\n",
    "docs = ['Açıklama projenin ortaklarından Rus enerji devi Gazprom dan geldi. Yıllık 63 milyar metreküp enerji',\n",
    "        'ilk günündeki 20 yarış heyecanlıydı, 109 puan toplayan Türkiye, 12 ülke arasında 9. oldu ve yarış tamamlandı',\n",
    "        'Cortananın yeni işletim sistemi Windows 10 un önemli bir parçası olduğunu belirten Microsoft ; Google Android ve iOS cihazlarındaki Dijital',\n",
    "        'Teknoloji devi Google, Android in MMM sürümüyle birlikte bir çok sistemsel hatasının düzeltileceğini',\n",
    "        'Siroz hastalığı ile ilgili detaylara dikkat çekerek, sağlıklı bir karaciğere sahip olmak hastalık için',\n",
    "        'Hastalık çoğu kez yıllarca doğru tanı konmaması veya ciddiye alınmaması sebebi ile kısırlaştırıcı etki yapabiliyor, kronik ağrı,',\n",
    "        'ilk 4 etaptan galibiyetle ayrılan 18 yaşındaki Razgatlıoğlu, Almanya daki yarışta 3. sırayı alarak ',\n",
    "        'Helal gıda pazarı sanki 860 milyar doların üzerinde'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WPT = nltk.WordPunctTokenizer()\n",
    "stop_word_list = nltk.corpus.stopwords.words('turkish')\n",
    "\n",
    "stop_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "eJ4y8IIuA_kw",
    "outputId": "5eea1fdf-ebdb-4130-83d1-972a05b1a49e"
   },
   "outputs": [],
   "source": [
    "def norm_doc(single_doc):\n",
    "    # TR: Dokümandan belirlenen özel karakterleri ve sayıları at\n",
    "    # EN: Remove special characters and numbers\n",
    "    single_doc = re.sub(\" \\d+\", \" \", single_doc)\n",
    "    pattern = r\"[{}]\".format(\",.;\") \n",
    "    single_doc = re.sub(pattern, \"\", single_doc) \n",
    "    # TR: Dokümanı küçük harflere çevir\n",
    "    # EN: Convert document to lowercase\n",
    "    single_doc = single_doc.lower()\n",
    "    single_doc = single_doc.strip()\n",
    "    # TR: Dokümanı token'larına ayır\n",
    "    # EN: Tokenize documents\n",
    "    tokens = WPT.tokenize(single_doc)\n",
    "    # TR: Stop-word listesindeki kelimeler hariç al\n",
    "    # EN: Filter out the stop-words \n",
    "    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n",
    "    # TR: Dokümanı tekrar oluştur\n",
    "    # EN: Reconstruct the document\n",
    "    single_doc = ' '.join(filtered_tokens)\n",
    "    return single_doc\n",
    "\n",
    "norm_docs = np.vectorize(norm_doc) #like magic :)\n",
    "normalized_documents = norm_docs(docs)\n",
    "print(normalized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TR: 1.Terim Sayma Adımları\n",
    "# EN: 1.Term Counting Steps\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BoW_Vector = CountVectorizer(min_df = 0., max_df = 1.)\n",
    "BoW_Matrix = BoW_Vector.fit_transform(normalized_documents)\n",
    "#print (BoW_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = BoW_Vector.get_feature_names()\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 801
    },
    "colab_type": "code",
    "id": "pbbYWJ-uJ0ds",
    "outputId": "4fd2d45d-d1de-4093-dcfb-fab72150b65e"
   },
   "outputs": [],
   "source": [
    "# TR: BoW_Vector içerisindeki tüm öznitelikleri al\n",
    "# EN: Fetch al features in BoW_Vector\n",
    "features = BoW_Vector.get_feature_names()\n",
    "print (\"features[0]:\" + features[0])\n",
    "print (\"features[10]:\" +features[10])\n",
    "\n",
    "BoW_Matrix = BoW_Matrix.toarray()\n",
    "print(BoW_Matrix)\n",
    "# TR: Doküman - öznitelik matrisini göster\n",
    "# EN: Print document by term matrice\n",
    "BoW_df = pd.DataFrame(BoW_Matrix, columns = features)\n",
    "BoW_df\n",
    "#print(BoW_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SJJgDizsKBGn",
    "outputId": "0f0c38f6-541b-4380-87fe-8b97bc8e0199"
   },
   "outputs": [],
   "source": [
    "# TR: 2.TFxIdf Hesaplama Adımları\n",
    "# EN: 2.TFxIdf Calculation Steps\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Tfidf_Vector = TfidfVectorizer(min_df = 0., max_df = 1., use_idf = True)\n",
    "\n",
    "Tfidf_Matrix = Tfidf_Vector.fit_transform(normalized_documents)\n",
    "Tfidf_Matrix = Tfidf_Matrix.toarray()\n",
    "print(np.round(Tfidf_Matrix, 3))\n",
    "# TR: Tfidf_Vector içerisindeki tüm öznitelikleri al\n",
    "# EN: Fetch al features in Tfidf_Vector\n",
    "features = Tfidf_Vector.get_feature_names()\n",
    "# TR: Doküman - öznitelik matrisini göster\n",
    "# EN: Print document by term matrice\n",
    "Tfidf_df = pd.DataFrame(np.round(Tfidf_Matrix, 3), columns = features)\n",
    "Tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAiaIoN6d7yX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TextProcessingPart1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
